\documentclass[twoside,11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{latexsym,amsmath,amssymb}
\usepackage{ngerman}
\usepackage{theorem}
\usepackage{dcolumn}
\usepackage{tikz}
\usetikzlibrary{trees}

\newcommand{\Frac}[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\newlength{\textwd}
\newlength{\oddsidemargintmp}
\newlength{\evensidemargintmp}
\newcommand{\hspaceof}[2]{\settowidth{\textwd}{#1}\mbox{\hspace{#2\textwd}}}
\newlength{\textht}
\newcommand{\vspaceof}[3]{\settoheight{\textht}{#1}\mbox{\raisebox{#2\textht}{#3}}}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}


\newenvironment{deflist}[1][\quad]%
{  \begin{list}{}{%
      \renewcommand{\makelabel}[1]{\textbf{##1}\hfil}%
      \settowidth{\labelwidth}{\textbf{#1}}%
      \setlength{\leftmargin}{\labelwidth}
      \addtolength{\leftmargin}{\labelsep}}}
{  \end{list}}


\newenvironment{Quote}% Definition of Quote
{  \begin{list}{}{%
      \setlength{\rightmargin}{0pt}}
      \item[]\ignorespaces}
{\unskip\end{list}}


\newtheorem{Cor}{Corollary}
\theoremstyle{break}
\theorembodyfont{\itshape}
\newtheorem{Def}[Cor]{Definition}
\theoremheaderfont{\scshape}

\newcolumntype{.}{D{.}{.}{-1}}


\pagestyle{headings}

\textwidth 15cm
\textheight 23cm
\oddsidemargin 1cm
\evensidemargin 0cm

\tikzset{
grow=left,
level 1/.style={sibling distance=5cm, level distance=3.0cm},
level 2/.style={sibling distance=3cm, level distance=4.0cm},
level 3/.style={sibling distance=2cm, level distance=4.0cm},
}

% Define styles for bags and leafs
\tikzstyle{bag} = [text width=4em, text centered]
\tikzstyle{end} = [circle, minimum width=3pt,fill, inner sep=0pt]

\begin{document}

\pagestyle{empty}
\begin{center}

    Rheinisch-Westfälische Technische Hochschule Aachen \\
    Lehrstuhl für Informatik VI \\
    Prof. Dr.-Ing. Hermann Ney\\[6ex]
    Proseminar Datenkompression im WS 2014/2015\\[12ex]

    \LARGE
    \textbf{Adaptive Huffman-Kodierung und Anwendungen} \\[6ex]
    \textit{Thomas Gatzweiler} \\[6ex]
    \Large
    Matrikelnummer 318947 \\[6ex]
    12. November 2014

    \vfill
    \Large Betreuer: Patrick Dötsch
\end{center}

\newpage
\
\newpage

\pagestyle{headings}
\tableofcontents
\listoftables
\listoffigures
\newpage
\pagestyle{empty}
\
\newpage
\pagestyle{headings}


\setlength{\parindent}{0pt}
\setlength{\parskip}{2ex plus 0.5ex minus 0.2ex}

%\begin{abstract}
%Diese Ausarbeitung enthält eine Einführung in die Funktionsweise der
%Huffman-Kodierung und im speziellen der adaptiven Huffman-Kodierung.
%\end{abstract}

\section{Einleitung}
Bei einer Datenübertragung mit eingeschränkter Bandbreite ist eine
Komprimierung der Daten von großem Vorteil.

Ein Problem der Huffman-Kodierung ist, dass die Wahrscheinlichkeiten
der Quellsymbole vor der Kodierung bekannt sein müssen. Wenn die zu
komprimierenden Daten lokal verfügbar sind, ist es möglich, zuerst die
Häufigkeiten der vorkommenden Quellsymbole zu analysieren und dann
die Daten zu kodieren. Handelt es sich aber um einen laufenden
Datenstrom, ist es nicht möglich die Häufig im vorraus zu ermitteln.
Eine Lösung für dieses Problem bietet die adaptive Huffman-Kodierung,
die sich laufend an die Häufigkeiten der Quellsymbole anpasst.

\section{Huffman-Kodierung}

Dieser Abschnitt gibt eine Einführung in die Hufmann-Kodierung, auf welche die
adaptive Huffman-Kodierung aufbaut. Der Abschnitt basiert auf \cite[S.
214-228]{Salomon:2010}.

Die Huffman-Kodierung ist eine stochastische Kodierung, das heißt, sie kodiert
Daten basierend auf der Häufigkeit der vorkommenden Quellsymbole. Häufig
vorkommenden Symbolen wird ein kürzeres Codewort zugewiesen als selteneren
Symbolen.

\subsection{Huffman-Baum}

Um Daten mit der Huffman-Kodierung zu komprimieren muss zuerst der sogenannte
Huffman-Baum aufgebaut werden. Es handelt sich dabei um einen Binärbaum

\begin{figure}
\centering
\begin{tikzpicture}
\node[bag]
    child {
        node[bag] {Bag 2}
            child {
                node[end, label=left:{test}] {}
                edge from parent
                node[below]  {$\frac{4}{9}$}
            }
            child {
                node[end, label=left:{test}] {}
                edge from parent
                node[below]  {$\frac{5}{9}$}
            }
            edge from parent
            node[below]  {$\frac{4}{7}$}
    }
    child {
        node[bag] {Bag 2}
        child {
                node[end, label=left:{test2}] {}
                edge from parent
                node[below]  {$\frac{3}{9}$}
            }
            child {
                node[end, label=left:{test3}] {}
                edge from parent
                node[below]  {$\frac{6}{9}$}
            }
        edge from parent
        node[below]  {$\frac{3}{7}$}
    };
\end{tikzpicture}
\caption{M1} \label{fig:M1}
\end{figure}

\subsection{Kodierung}
Nachdem der Huffman-Baum generiert wurde, kann er zur Kodierung von Daten
verwendet werden.

\subsection{Dekodierung}
Auch für die Dekodierung wird der Huffman-Baum verwendet. Dazu muss der
Dekodierer die Häufigkeitsverteilung der Quellsymbole kennen

\subsection{Mittlere Codewort-Länge}


\section{Adaptive Huffman-Kodierung}
Die adaptive Huffman-Kodierung aktualisiert laufend den Huffman-Baum.

Da anfangs noch keine Häufigkeiten der auftauchenden Wörter Symbole
bekannt sind, wird mit einem leeren Baum begonnen. Mit jeden neuen
Wort wird der Baum entsprechend der neuen
Wahrscheinlichkeitsverteilung aktualisiert. Dieser Schritt wird auch
im Dekodierer durchgeführt, so dass eine Übertragung des Huffman-Baums
nicht nötig ist.

Der Vorteil der adaptiven Huffman-Kodierung ist die Möglichkeit einen
Datenstrom zu komprimieren ohne vorher Informationen über die
Häufigkeitsverteilung der Daten zu besitzen. Das macht es auch möglich
Dateien in nur einem Durchgang zu komprimieren, ohne voher die
Häufigkeiten der vorkommenden Wörter zu analysieren. Ein Nachteil ist,
dass diese Methode anfällig für Übertragungsfehler ist, da die
Hufmann-Bäume im Encoder und Decoder in diesem Fall divergieren können.

\subsection{Kodierung}

\subsection{Dekodierung}

\subsection{Aktualisierung des Huffman-Baums}

% Beispiel

\subsection{Überlauf der Häufigkeitszähler}

\subsection{Überlauf der Codeworte}

% -> Salomon 5.2.7 Height of a Huffman Tree
% Betrifft nur den Kodierprozess

\subsection{Algorithmus von Vitter}

\section{Anwendungen}

% -> Salomon 5.2.9 Is Huffman Coding Dead

Die hier vorgestellten Anwendungsfälle basieren auf den Beispielen aus
\cite{Sayood:2006}.

% -> Sayood 3.8 Applications of Huffman Coding
\subsection{Textkomprimierung}

\subsection{Verlustfreie Bildkomprimierung}

\subsection{Audiokomprimierung}


Test \cite{Salomon:2010}  \cite{Williams:1991}

\addcontentsline{toc}{section}{Literaturverzeichnis}
\bibliographystyle{plain}
\bibliography{adaptive_huffman}

\end{document}
